#####################################################################################
# file_aggregator.yaml
#####################################################################################
#
# This workflow:
#    - creates a given directory as a workspace
#    - takes two file names, an output file name, and output file format as input
#    - Create a file that combines two separate input files with the distinct columns 
#      and all records from both
#    - wraps up the workflow
#
# Example command-line usage:
# kurator -f file_aggregator.yaml 
#         -p workspace=./file_aggregator_workspace
#         -p inputfile1=../data/tests/test_aggregate_1.csv
#         -p inputfile2=../data/tests/test_aggregate_2.csv
#         -p outputfile=aggregated_file.csv
#         -p format=csv
#         -l DEBUG (optional)
#
#####################################################################################
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# __author__ = "John Wieczorek"
# __copyright__ = "Copyright 2016 President and Fellows of Harvard College"
# __version__ = "file_aggregator.yaml 2017-01-05T16:34-03:00"

imports:

- classpath:/org/kurator/akka/types.yaml

# Definitions of the Workflow and actors
components:

### The named workflow ###
- id: FileAggregator
  type: Workflow
  properties:
    actors:
      # Actors invoked in the workflow. Every actor that will be invoked must be on this
      # list. Though the order does not matter, it is helpful to keep the list in more
      # or less the order in which they'll be invoked, for clarity.
      - !ref MakeWorkspace
      - !ref AggregateFiles
      - !ref WrapUp
    # Each parameter defined here enters the workflow from the command line and is 
    # delivered in the options dictionary of the specified actor.
    parameters:
      # Accept a parameter called workspace from the command line.
      workspace:
        # Set the workspace in the options dictionary of MakeWorkspace from the value
        # of the workspace parameter given on the command line.
        actor: !ref MakeWorkspace
        parameter: workspace
      # Accept a parameter called inputfile1 from the command line.
      inputfile1:
        # Set the inputfile1 in the options dictionary of ConstructCompositeHeader from the 
        # value of the inputfile1 parameter given on the command line.
        actor: !ref AggregateFiles
        parameter: inputfile1
      # Accept a parameter called inputfile2 from the command line.
      inputfile2:
        # Set the inputfile2 in the options dictionary of ConstructCompositeHeader from the 
        # value of the inputfile2 parameter given on the command line.
        actor: !ref AggregateFiles
        parameter: inputfile2
      # Accept a parameter called outputfile from the command line.
      outputfile:
        # Set the outputfile in the options dictionary of ConstructCompositeHeader from the 
        # value of the outputfile parameter given on the command line.
        actor: !ref AggregateFiles
        parameter: outputfile
      # Accept a parameter called format from the command line.
      format:
        # Set the format in the options dictionary of Darwinize from the value
        # of the format parameter given on the command line.
        actor: !ref AggregateFiles
        parameter: format

# Inline python actor to make a workspace on the fly to use for writing temporary 
# if one is not supplied in the workflow-defined parameters. It creates a unique
# workspace if a workspace location is not explicitly provided, or if the provided
# one does not exist.
- id: MakeWorkspace
  type: NativePythonActor
  properties:
    onStart: on_start
    # Inline python code to run.
    code: |
        import uuid
        import os
        # The function to run when an on_start message is received. Accepts a dictionary
        # of options.
        def on_start(options):
            actor = 'MakeWorkspace'
            print '### Started %s ###' % actor
            for key, value in options.iteritems():
                print '%s: %s' % (key, value)
            options['success']=True
            if options.has_key('workspace') == False:
                options['workspace'] ='./workspace_'+str(uuid.uuid1())
            if not os.path.exists(options['workspace']):
                os.makedirs(options['workspace'])
            if not os.path.exists(options['workspace']):
                options['success']=False
                options['message']='Unable to create workspace at %s' % options[workspace]
            else:
                options['message']='Created workspace %s' % options['workspace']
            return options

# Create a new file by joining two files. Output file has a header composed of the fields
# from both files.
- id: AggregateFiles
  type: NativePythonActor
  properties:
    onData: on_data
    # Inline python code to run.
    code: |
        # The function to run when an on_data message is received. Accepts a dictionary
        # of options.
        # An optimization would be to download only those files that are needed.
        # Another optimization would be to have zip files of the vocabs to download
        # and unzip.
        import os
        import uuid
        from kurator_dwca.slugify import slugify
        from kurator_dwca.dwca_utils import read_header
        from kurator_dwca.dwca_utils import merge_headers
        from kurator_dwca.dwca_utils import csv_file_dialect
        from kurator_dwca.dwca_utils import csv_file_encoding
        from kurator_dwca.dwca_utils import utf8_data_encoder
        from kurator_dwca.dwca_utils import csv_dialect
        from kurator_dwca.dwca_utils import tsv_dialect

        try:
            import unicodecsv as csv
        except ImportError:
            import warnings
            s = "The unicodecsv package is required.\n"
            s += "pip install unicodecsv\n"
            s += "$JYTHON_HOME/bin/pip install unicodecsv"
            warnings.warn(s)

        def on_data(options):
            actor = 'AggregateFiles'
            print '### Started %s ###' % actor
            for key, value in options.iteritems():
                print '%s: %s' % (key, value)
            outputoptions = {}
            outputoptions['success'] = True
            outputoptions['message'] = None
            outputoptions['workspace'] = options['workspace']
            outputoptions['artifacts'] = {}

            try:
                format = options['format']
            except:
                pass

            if format is None or len(format)==0:
                format = 'txt'

            if format == 'txt':
                outputdialect = tsv_dialect()
            else:
                outputdialect = csv_dialect()

            try:
                outputfile = options['outputfile']
            except:
                outputfile = None

            if outputfile is None or len(outputfile.strip())==0:
                outputfile = '%s/aggregated_%s.%s' % \
                  (options['workspace'].rstrip('/'), str(uuid.uuid1()), format)
            else:
                outputfile = '%s/%s' % (options['workspace'].rstrip('/'), outputfile)
            print 'outputfile: %s' % outputfile

            inputfile1 = options['inputfile1']
            inputfile2 = options['inputfile2']

            if inputfile1 is None or len(inputfile1)==0:
                outputoptions['message'] = 'input file 1 not given'
                outputoptions['success'] = False
                return outputoptions

            if inputfile2 is None or len(inputfile2)==0:
                outputoptions['message'] = 'input file 2 not given'
                outputoptions['success'] = False
                return outputoptions

            if os.path.isfile(inputfile1) == False:
                message = 'Input file %s not found.' % (inputfile1)
                outputoptions['message'] = message
                outputoptions['success'] = False
                return outputoptions

            if os.path.isfile(inputfile2) == False:
                message = 'Input file %s not found.' % (inputfile2)
                outputoptions['message'] = message
                outputoptions['success'] = False
                return outputoptions

            # Read the headers of the two files and let read_header figure out the dialects and
            # encodings.
            encoding1 = csv_file_encoding(inputfile1)
            encoding2 = csv_file_encoding(inputfile2)

            header1 = read_header(inputfile1, encoding=encoding1)
            header2 = read_header(inputfile2, encoding=encoding2)

            compositeheader = merge_headers(header1, header2)

            print 'header1: %s %s' % (len(header1), header1)
            print 'header2: %s %s' % (len(header2), header2)
            print 'compositeheader: %s %s' % (len(compositeheader),compositeheader)

            files = []
            files.append(inputfile1)
            files.append(inputfile2)
            
            aggregaterowcount=0

            # Open a file to write the aggregated results in chosen format and utf-8.
            with open(outputfile, 'w') as outfile:
                writer = csv.DictWriter(outfile, dialect=outputdialect, encoding='utf-8', 
                    fieldnames=compositeheader, extrasaction='ignore')
                writer.writeheader()

                file = inputfile1
                inputdialect = csv_file_dialect(file)
                with open(file, 'rU') as inputfile:
                    reader = csv.DictReader(utf8_data_encoder(inputfile, encoding1), 
                        dialect=inputdialect, fieldnames=header1)
                    # Skip the header row
                    reader.next()
                    for line in reader:
                        try:
                            writer.writerow(line)
                            aggregaterowcount += 1
                        except Exception, e:
                            outputoptions['message'] = 'failed to write line:\n%s\n' % line
                            outputoptions['message'] += 'to file %s.' % file
                            outputoptions['message'] += '%s' % e
                            outputoptions['success'] = False
                            return outputoptions

                file = inputfile2
                inputdialect = csv_file_dialect(file)
                with open(file, 'rU') as inputfile:
                    reader = csv.DictReader(utf8_data_encoder(inputfile, encoding2), 
                        dialect=inputdialect, fieldnames=header2)
                    # Skip the header row
                    reader.next()
                    for line in reader:
                        try:
                            writer.writerow(line)
                            aggregaterowcount += 1
                        except:
                            outputoptions['message'] = 'failed to write line:\n%s\n' % line
                            outputoptions['message'] += 'to file %s.' % file
                            outputoptions['success'] = False
                            return outputoptions

            if outputoptions['success'] == False:
                return outputoptions
            artifact_key = 'aggregated_file'
            outputoptions['artifacts'][artifact_key] = outputfile
            return outputoptions
    # A list of parameters to get from the options dictionary passed from an 
    # upstream actor.
    inputs:
      # Get the workspace for this actor from the workspace in the options dictionary.
      workspace : workspace
    # The "upstream" actor from which to receive a message.
    listensTo:
      - !ref MakeWorkspace

# Inline python actor to take care of any unfinished business and finish the workflow.
- id: WrapUp
  type: NativePythonActor
  properties:
    onData: on_data
    # Inline python code to run.
    code: |
        # The function to run when an on_data message is received. Accepts a dictionary
        # of options.
        def on_data(options):
            actor = 'WrapUp'
            print '### Started %s ###' % actor
            for key, value in options.iteritems():
                if key == 'artifacts':
                    print 'artifacts:'
                    keylist = []
                    for akey, avalue in options[key].iteritems():
                        keylist.append(akey)
                    sortedkeylist = sorted(keylist)
                    for skey in sortedkeylist:
                        print '  %s: %s' % (skey, options[key][skey])
                else:
                    print '%s: %s' % (key, value)
            print '### Finished Wrapup ###'
    # A list of parameters to get from the options dictionary passed from an 
    # upstream actor.
    inputs:
        # Get the workspace for this actor from the workspace in the options dictionary.
        workspace: workspace
        vocabfile: vocabfile
        addedvalues: addedvalues
        # Get the success state from the options dictionary of the previous step
        success: previoussuccess
        # Get the message from the options dictionary of the previous step
        message: previousmessage
    parameters:
      # Show the name of the upstream actor.
      messagefrom: 'AggregateFiles'
    # The "upstream" actor from which to receive a message.
    listensTo:
      - !ref AggregateFiles
